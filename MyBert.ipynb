{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MyBert.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPM02kQGiUneIgiYEuAZ156",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/m109103/bert/blob/main/MyBert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "g1lnuesyxCqE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0eab472f-68e5-4e3d-982a-42468ffd3d58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-bert\n",
            "  Downloading keras-bert-0.89.0.tar.gz (25 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-bert) (1.21.5)\n",
            "Collecting keras-transformer==0.40.0\n",
            "  Downloading keras-transformer-0.40.0.tar.gz (9.7 kB)\n",
            "Collecting keras-pos-embd==0.13.0\n",
            "  Downloading keras-pos-embd-0.13.0.tar.gz (5.6 kB)\n",
            "Collecting keras-multi-head==0.29.0\n",
            "  Downloading keras-multi-head-0.29.0.tar.gz (13 kB)\n",
            "Collecting keras-layer-normalization==0.16.0\n",
            "  Downloading keras-layer-normalization-0.16.0.tar.gz (3.9 kB)\n",
            "Collecting keras-position-wise-feed-forward==0.8.0\n",
            "  Downloading keras-position-wise-feed-forward-0.8.0.tar.gz (4.1 kB)\n",
            "Collecting keras-embed-sim==0.10.0\n",
            "  Downloading keras-embed-sim-0.10.0.tar.gz (3.6 kB)\n",
            "Collecting keras-self-attention==0.51.0\n",
            "  Downloading keras-self-attention-0.51.0.tar.gz (11 kB)\n",
            "Building wheels for collected packages: keras-bert, keras-transformer, keras-embed-sim, keras-layer-normalization, keras-multi-head, keras-pos-embd, keras-position-wise-feed-forward, keras-self-attention\n",
            "  Building wheel for keras-bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-bert: filename=keras_bert-0.89.0-py3-none-any.whl size=33517 sha256=78e58a1616455e38e55d46109aed31988e3d04398076b567ea789c91fb02c74c\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/e8/45/842b3a39831261aef9154b907eacbc4ac99499a99ae829b06f\n",
            "  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-transformer: filename=keras_transformer-0.40.0-py3-none-any.whl size=12305 sha256=9112088e482783158283ca1486c3d35491eb8f4bf8fd3252be7bb27c216f4209\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/68/26/692ed21edd832833c3b0a0e21615bcacd99ca458b3f9ed571f\n",
            "  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.10.0-py3-none-any.whl size=3960 sha256=bb375ba2882162682877b6b1c21b7c33f2334782dc76e6ba15becd70bd7a6edf\n",
            "  Stored in directory: /root/.cache/pip/wheels/81/67/b5/d847588d075895281e1cf5590f819bd4cf076a554872268bd5\n",
            "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.16.0-py3-none-any.whl size=4668 sha256=47d42f6bd3b97f5cec33e496ac6af0e665bbee128b08f9a0c36c8a06bae52fdd\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/5d/1c/2e619f594f69fbcf8bc20943b27d414871c409be053994813e\n",
            "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-multi-head: filename=keras_multi_head-0.29.0-py3-none-any.whl size=14993 sha256=87bdf03fd618a98dd2138dd3a592cc6beaea46d874a6c39da74780f36edc1298\n",
            "  Stored in directory: /root/.cache/pip/wheels/86/aa/3c/9d15d24005179dae08ff291ce99c754b296347817d076fd9fb\n",
            "  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.13.0-py3-none-any.whl size=6962 sha256=733e163baef5369596bc1f9a4d79429af99989ca9ca677634950a03c458aef12\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/c1/a0/dc44fcf68c857b7ff6be9a97e675e5adf51022eff1169b042f\n",
            "  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.8.0-py3-none-any.whl size=4983 sha256=e6d2b6f6802e19fa256b40e942bdf30038eef6e5102e7659880c4f4931be0700\n",
            "  Stored in directory: /root/.cache/pip/wheels/c2/75/6f/d42f6e051506f442daeba53ff1e2d21a5f20ef8c411610f2bb\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-self-attention: filename=keras_self_attention-0.51.0-py3-none-any.whl size=18912 sha256=e0b1dadfac9b4cc526e8b3191929750fa4201df70cd07990fd45578106582a69\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/b1/a8/5ee00cc137940b2f6fa198212e8f45d813d0e0d9c3a04035a3\n",
            "Successfully built keras-bert keras-transformer keras-embed-sim keras-layer-normalization keras-multi-head keras-pos-embd keras-position-wise-feed-forward keras-self-attention\n",
            "Installing collected packages: keras-self-attention, keras-position-wise-feed-forward, keras-pos-embd, keras-multi-head, keras-layer-normalization, keras-embed-sim, keras-transformer, keras-bert\n",
            "Successfully installed keras-bert-0.89.0 keras-embed-sim-0.10.0 keras-layer-normalization-0.16.0 keras-multi-head-0.29.0 keras-pos-embd-0.13.0 keras-position-wise-feed-forward-0.8.0 keras-self-attention-0.51.0 keras-transformer-0.40.0\n"
          ]
        }
      ],
      "source": [
        "!pip install keras-bert"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCTpza-0LRzB",
        "outputId": "bf76f8e4-4575-4162-b545-fd485ba92b52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import timeit\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print(\n",
        "      '\\n\\nThis error most likely means that this notebook is not '\n",
        "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "  raise SystemError('GPU device not found')\n",
        "\n",
        "def cpu():\n",
        "  with tf.device('/cpu:0'):\n",
        "    random_image_cpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)\n",
        "    return tf.math.reduce_sum(net_cpu)\n",
        "\n",
        "def gpu():\n",
        "  with tf.device('/device:GPU:0'):\n",
        "    random_image_gpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n",
        "    return tf.math.reduce_sum(net_gpu)\n",
        "  \n",
        "# We run each op once to warm up; see: https://stackoverflow.com/a/45067900\n",
        "cpu()\n",
        "gpu()\n",
        "\n",
        "# Run the op several times.\n",
        "print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
        "      '(batch x height x width x channel). Sum of ten runs.')\n",
        "print('CPU (s):')\n",
        "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
        "print(cpu_time)\n",
        "print('GPU (s):')\n",
        "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
        "print(gpu_time)\n",
        "print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3y0Vg7WwLkZN",
        "outputId": "d3c810d8-cff4-4003-e6b9-0c77ecc8d225"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images (batch x height x width x channel). Sum of ten runs.\n",
            "CPU (s):\n",
            "2.900214824000045\n",
            "GPU (s):\n",
            "0.041853807999927994\n",
            "GPU speedup over CPU: 69x\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall keras-nightly"
      ],
      "metadata": {
        "id": "KMHVNi43y1wo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y tensorflow"
      ],
      "metadata": {
        "id": "xG5Bulg4zAas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-gpu==2.2.0"
      ],
      "metadata": {
        "id": "mg4doAqjzNsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras==2.3.0"
      ],
      "metadata": {
        "id": "2gyR3gzezglz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-bert==0.82.0"
      ],
      "metadata": {
        "id": "OnVKby32zvXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "nWoWoFQhz335",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76af6ff4-d8ae-4edf-b22c-4da6c846a701"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Apr 16 07:15:40 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P0    27W /  70W |   1838MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive  \n",
        "drive.mount('/content/gdrive')  "
      ],
      "metadata": {
        "id": "mQChBWn7C2oP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo lsb_release -a"
      ],
      "metadata": {
        "collapsed": true,
        "id": "vY2Xm8uG-sR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from keras_bert import (\n",
        "    load_vocabulary,\n",
        "    load_trained_model_from_checkpoint,\n",
        "    Tokenizer,\n",
        "    get_checkpoint_paths,\n",
        ")\n",
        "from keras_bert.datasets import get_pretrained, PretrainedList"
      ],
      "metadata": {
        "id": "PZOcUU4i0IsC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9X5dvxWNQ2ML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SPLIT_PORTION = 0.8  # 指定訓練資料與測試資料的比例\n",
        "BATCH_SIZE = 2  # batch size建議不要設得太大，不然很有可能out of memory\n",
        "EPOCHS = 5 # epoch 5次其實就很夠了，當然你可以嘗試再大一點，只是訓練要更久"
      ],
      "metadata": {
        "id": "ujxw-JrC0OHS"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = get_pretrained(PretrainedList.chinese_base)\n",
        "paths = get_checkpoint_paths(model_path)\n",
        "bert_model = load_trained_model_from_checkpoint(\n",
        "    paths.config, paths.checkpoint, training=False, seq_len=None\n",
        ")\n",
        "bert_model.summary(line_length=120)"
      ],
      "metadata": {
        "id": "RW01f8ZM0ZyT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0b702c8-e74b-402d-823b-f3031d5812f3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/bert_models/2018_11_03/chinese_L-12_H-768_A-12.zip\n",
            "381894656/381892918 [==============================] - 5s 0us/step\n",
            "381902848/381892918 [==============================] - 5s 0us/step\n",
            "Model: \"model_1\"\n",
            "________________________________________________________________________________________________________________________\n",
            " Layer (type)                          Output Shape               Param #       Connected to                            \n",
            "========================================================================================================================\n",
            " Input-Token (InputLayer)              [(None, None)]             0             []                                      \n",
            "                                                                                                                        \n",
            " Input-Segment (InputLayer)            [(None, None)]             0             []                                      \n",
            "                                                                                                                        \n",
            " Embedding-Token (TokenEmbedding)      [(None, None, 768),        16226304      ['Input-Token[0][0]']                   \n",
            "                                        (21128, 768)]                                                                   \n",
            "                                                                                                                        \n",
            " Embedding-Segment (Embedding)         (None, None, 768)          1536          ['Input-Segment[0][0]']                 \n",
            "                                                                                                                        \n",
            " Embedding-Token-Segment (Add)         (None, None, 768)          0             ['Embedding-Token[0][0]',               \n",
            "                                                                                 'Embedding-Segment[0][0]']             \n",
            "                                                                                                                        \n",
            " Embedding-Position (PositionEmbedding  (None, None, 768)         393216        ['Embedding-Token-Segment[0][0]']       \n",
            " )                                                                                                                      \n",
            "                                                                                                                        \n",
            " Embedding-Dropout (Dropout)           (None, None, 768)          0             ['Embedding-Position[0][0]']            \n",
            "                                                                                                                        \n",
            " Embedding-Norm (LayerNormalization)   (None, None, 768)          1536          ['Embedding-Dropout[0][0]']             \n",
            "                                                                                                                        \n",
            " Encoder-1-MultiHeadSelfAttention (Mul  (None, None, 768)         2362368       ['Embedding-Norm[0][0]']                \n",
            " tiHeadAttention)                                                                                                       \n",
            "                                                                                                                        \n",
            " Encoder-1-MultiHeadSelfAttention-Drop  (None, None, 768)         0             ['Encoder-1-MultiHeadSelfAttention[0][0]\n",
            " out (Dropout)                                                                  ']                                      \n",
            "                                                                                                                        \n",
            " Encoder-1-MultiHeadSelfAttention-Add   (None, None, 768)         0             ['Embedding-Norm[0][0]',                \n",
            " (Add)                                                                           'Encoder-1-MultiHeadSelfAttention-Dropo\n",
            "                                                                                ut[0][0]']                              \n",
            "                                                                                                                        \n",
            " Encoder-1-MultiHeadSelfAttention-Norm  (None, None, 768)         1536          ['Encoder-1-MultiHeadSelfAttention-Add[0\n",
            "  (LayerNormalization)                                                          ][0]']                                  \n",
            "                                                                                                                        \n",
            " Encoder-1-FeedForward (FeedForward)   (None, None, 768)          4722432       ['Encoder-1-MultiHeadSelfAttention-Norm[\n",
            "                                                                                0][0]']                                 \n",
            "                                                                                                                        \n",
            " Encoder-1-FeedForward-Dropout (Dropou  (None, None, 768)         0             ['Encoder-1-FeedForward[0][0]']         \n",
            " t)                                                                                                                     \n",
            "                                                                                                                        \n",
            " Encoder-1-FeedForward-Add (Add)       (None, None, 768)          0             ['Encoder-1-MultiHeadSelfAttention-Norm[\n",
            "                                                                                0][0]',                                 \n",
            "                                                                                 'Encoder-1-FeedForward-Dropout[0][0]'] \n",
            "                                                                                                                        \n",
            " Encoder-1-FeedForward-Norm (LayerNorm  (None, None, 768)         1536          ['Encoder-1-FeedForward-Add[0][0]']     \n",
            " alization)                                                                                                             \n",
            "                                                                                                                        \n",
            " Encoder-2-MultiHeadSelfAttention (Mul  (None, None, 768)         2362368       ['Encoder-1-FeedForward-Norm[0][0]']    \n",
            " tiHeadAttention)                                                                                                       \n",
            "                                                                                                                        \n",
            " Encoder-2-MultiHeadSelfAttention-Drop  (None, None, 768)         0             ['Encoder-2-MultiHeadSelfAttention[0][0]\n",
            " out (Dropout)                                                                  ']                                      \n",
            "                                                                                                                        \n",
            " Encoder-2-MultiHeadSelfAttention-Add   (None, None, 768)         0             ['Encoder-1-FeedForward-Norm[0][0]',    \n",
            " (Add)                                                                           'Encoder-2-MultiHeadSelfAttention-Dropo\n",
            "                                                                                ut[0][0]']                              \n",
            "                                                                                                                        \n",
            " Encoder-2-MultiHeadSelfAttention-Norm  (None, None, 768)         1536          ['Encoder-2-MultiHeadSelfAttention-Add[0\n",
            "  (LayerNormalization)                                                          ][0]']                                  \n",
            "                                                                                                                        \n",
            " Encoder-2-FeedForward (FeedForward)   (None, None, 768)          4722432       ['Encoder-2-MultiHeadSelfAttention-Norm[\n",
            "                                                                                0][0]']                                 \n",
            "                                                                                                                        \n",
            " Encoder-2-FeedForward-Dropout (Dropou  (None, None, 768)         0             ['Encoder-2-FeedForward[0][0]']         \n",
            " t)                                                                                                                     \n",
            "                                                                                                                        \n",
            " Encoder-2-FeedForward-Add (Add)       (None, None, 768)          0             ['Encoder-2-MultiHeadSelfAttention-Norm[\n",
            "                                                                                0][0]',                                 \n",
            "                                                                                 'Encoder-2-FeedForward-Dropout[0][0]'] \n",
            "                                                                                                                        \n",
            " Encoder-2-FeedForward-Norm (LayerNorm  (None, None, 768)         1536          ['Encoder-2-FeedForward-Add[0][0]']     \n",
            " alization)                                                                                                             \n",
            "                                                                                                                        \n",
            " Encoder-3-MultiHeadSelfAttention (Mul  (None, None, 768)         2362368       ['Encoder-2-FeedForward-Norm[0][0]']    \n",
            " tiHeadAttention)                                                                                                       \n",
            "                                                                                                                        \n",
            " Encoder-3-MultiHeadSelfAttention-Drop  (None, None, 768)         0             ['Encoder-3-MultiHeadSelfAttention[0][0]\n",
            " out (Dropout)                                                                  ']                                      \n",
            "                                                                                                                        \n",
            " Encoder-3-MultiHeadSelfAttention-Add   (None, None, 768)         0             ['Encoder-2-FeedForward-Norm[0][0]',    \n",
            " (Add)                                                                           'Encoder-3-MultiHeadSelfAttention-Dropo\n",
            "                                                                                ut[0][0]']                              \n",
            "                                                                                                                        \n",
            " Encoder-3-MultiHeadSelfAttention-Norm  (None, None, 768)         1536          ['Encoder-3-MultiHeadSelfAttention-Add[0\n",
            "  (LayerNormalization)                                                          ][0]']                                  \n",
            "                                                                                                                        \n",
            " Encoder-3-FeedForward (FeedForward)   (None, None, 768)          4722432       ['Encoder-3-MultiHeadSelfAttention-Norm[\n",
            "                                                                                0][0]']                                 \n",
            "                                                                                                                        \n",
            " Encoder-3-FeedForward-Dropout (Dropou  (None, None, 768)         0             ['Encoder-3-FeedForward[0][0]']         \n",
            " t)                                                                                                                     \n",
            "                                                                                                                        \n",
            " Encoder-3-FeedForward-Add (Add)       (None, None, 768)          0             ['Encoder-3-MultiHeadSelfAttention-Norm[\n",
            "                                                                                0][0]',                                 \n",
            "                                                                                 'Encoder-3-FeedForward-Dropout[0][0]'] \n",
            "                                                                                                                        \n",
            " Encoder-3-FeedForward-Norm (LayerNorm  (None, None, 768)         1536          ['Encoder-3-FeedForward-Add[0][0]']     \n",
            " alization)                                                                                                             \n",
            "                                                                                                                        \n",
            " Encoder-4-MultiHeadSelfAttention (Mul  (None, None, 768)         2362368       ['Encoder-3-FeedForward-Norm[0][0]']    \n",
            " tiHeadAttention)                                                                                                       \n",
            "                                                                                                                        \n",
            " Encoder-4-MultiHeadSelfAttention-Drop  (None, None, 768)         0             ['Encoder-4-MultiHeadSelfAttention[0][0]\n",
            " out (Dropout)                                                                  ']                                      \n",
            "                                                                                                                        \n",
            " Encoder-4-MultiHeadSelfAttention-Add   (None, None, 768)         0             ['Encoder-3-FeedForward-Norm[0][0]',    \n",
            " (Add)                                                                           'Encoder-4-MultiHeadSelfAttention-Dropo\n",
            "                                                                                ut[0][0]']                              \n",
            "                                                                                                                        \n",
            " Encoder-4-MultiHeadSelfAttention-Norm  (None, None, 768)         1536          ['Encoder-4-MultiHeadSelfAttention-Add[0\n",
            "  (LayerNormalization)                                                          ][0]']                                  \n",
            "                                                                                                                        \n",
            " Encoder-4-FeedForward (FeedForward)   (None, None, 768)          4722432       ['Encoder-4-MultiHeadSelfAttention-Norm[\n",
            "                                                                                0][0]']                                 \n",
            "                                                                                                                        \n",
            " Encoder-4-FeedForward-Dropout (Dropou  (None, None, 768)         0             ['Encoder-4-FeedForward[0][0]']         \n",
            " t)                                                                                                                     \n",
            "                                                                                                                        \n",
            " Encoder-4-FeedForward-Add (Add)       (None, None, 768)          0             ['Encoder-4-MultiHeadSelfAttention-Norm[\n",
            "                                                                                0][0]',                                 \n",
            "                                                                                 'Encoder-4-FeedForward-Dropout[0][0]'] \n",
            "                                                                                                                        \n",
            " Encoder-4-FeedForward-Norm (LayerNorm  (None, None, 768)         1536          ['Encoder-4-FeedForward-Add[0][0]']     \n",
            " alization)                                                                                                             \n",
            "                                                                                                                        \n",
            " Encoder-5-MultiHeadSelfAttention (Mul  (None, None, 768)         2362368       ['Encoder-4-FeedForward-Norm[0][0]']    \n",
            " tiHeadAttention)                                                                                                       \n",
            "                                                                                                                        \n",
            " Encoder-5-MultiHeadSelfAttention-Drop  (None, None, 768)         0             ['Encoder-5-MultiHeadSelfAttention[0][0]\n",
            " out (Dropout)                                                                  ']                                      \n",
            "                                                                                                                        \n",
            " Encoder-5-MultiHeadSelfAttention-Add   (None, None, 768)         0             ['Encoder-4-FeedForward-Norm[0][0]',    \n",
            " (Add)                                                                           'Encoder-5-MultiHeadSelfAttention-Dropo\n",
            "                                                                                ut[0][0]']                              \n",
            "                                                                                                                        \n",
            " Encoder-5-MultiHeadSelfAttention-Norm  (None, None, 768)         1536          ['Encoder-5-MultiHeadSelfAttention-Add[0\n",
            "  (LayerNormalization)                                                          ][0]']                                  \n",
            "                                                                                                                        \n",
            " Encoder-5-FeedForward (FeedForward)   (None, None, 768)          4722432       ['Encoder-5-MultiHeadSelfAttention-Norm[\n",
            "                                                                                0][0]']                                 \n",
            "                                                                                                                        \n",
            " Encoder-5-FeedForward-Dropout (Dropou  (None, None, 768)         0             ['Encoder-5-FeedForward[0][0]']         \n",
            " t)                                                                                                                     \n",
            "                                                                                                                        \n",
            " Encoder-5-FeedForward-Add (Add)       (None, None, 768)          0             ['Encoder-5-MultiHeadSelfAttention-Norm[\n",
            "                                                                                0][0]',                                 \n",
            "                                                                                 'Encoder-5-FeedForward-Dropout[0][0]'] \n",
            "                                                                                                                        \n",
            " Encoder-5-FeedForward-Norm (LayerNorm  (None, None, 768)         1536          ['Encoder-5-FeedForward-Add[0][0]']     \n",
            " alization)                                                                                                             \n",
            "                                                                                                                        \n",
            " Encoder-6-MultiHeadSelfAttention (Mul  (None, None, 768)         2362368       ['Encoder-5-FeedForward-Norm[0][0]']    \n",
            " tiHeadAttention)                                                                                                       \n",
            "                                                                                                                        \n",
            " Encoder-6-MultiHeadSelfAttention-Drop  (None, None, 768)         0             ['Encoder-6-MultiHeadSelfAttention[0][0]\n",
            " out (Dropout)                                                                  ']                                      \n",
            "                                                                                                                        \n",
            " Encoder-6-MultiHeadSelfAttention-Add   (None, None, 768)         0             ['Encoder-5-FeedForward-Norm[0][0]',    \n",
            " (Add)                                                                           'Encoder-6-MultiHeadSelfAttention-Dropo\n",
            "                                                                                ut[0][0]']                              \n",
            "                                                                                                                        \n",
            " Encoder-6-MultiHeadSelfAttention-Norm  (None, None, 768)         1536          ['Encoder-6-MultiHeadSelfAttention-Add[0\n",
            "  (LayerNormalization)                                                          ][0]']                                  \n",
            "                                                                                                                        \n",
            " Encoder-6-FeedForward (FeedForward)   (None, None, 768)          4722432       ['Encoder-6-MultiHeadSelfAttention-Norm[\n",
            "                                                                                0][0]']                                 \n",
            "                                                                                                                        \n",
            " Encoder-6-FeedForward-Dropout (Dropou  (None, None, 768)         0             ['Encoder-6-FeedForward[0][0]']         \n",
            " t)                                                                                                                     \n",
            "                                                                                                                        \n",
            " Encoder-6-FeedForward-Add (Add)       (None, None, 768)          0             ['Encoder-6-MultiHeadSelfAttention-Norm[\n",
            "                                                                                0][0]',                                 \n",
            "                                                                                 'Encoder-6-FeedForward-Dropout[0][0]'] \n",
            "                                                                                                                        \n",
            " Encoder-6-FeedForward-Norm (LayerNorm  (None, None, 768)         1536          ['Encoder-6-FeedForward-Add[0][0]']     \n",
            " alization)                                                                                                             \n",
            "                                                                                                                        \n",
            " Encoder-7-MultiHeadSelfAttention (Mul  (None, None, 768)         2362368       ['Encoder-6-FeedForward-Norm[0][0]']    \n",
            " tiHeadAttention)                                                                                                       \n",
            "                                                                                                                        \n",
            " Encoder-7-MultiHeadSelfAttention-Drop  (None, None, 768)         0             ['Encoder-7-MultiHeadSelfAttention[0][0]\n",
            " out (Dropout)                                                                  ']                                      \n",
            "                                                                                                                        \n",
            " Encoder-7-MultiHeadSelfAttention-Add   (None, None, 768)         0             ['Encoder-6-FeedForward-Norm[0][0]',    \n",
            " (Add)                                                                           'Encoder-7-MultiHeadSelfAttention-Dropo\n",
            "                                                                                ut[0][0]']                              \n",
            "                                                                                                                        \n",
            " Encoder-7-MultiHeadSelfAttention-Norm  (None, None, 768)         1536          ['Encoder-7-MultiHeadSelfAttention-Add[0\n",
            "  (LayerNormalization)                                                          ][0]']                                  \n",
            "                                                                                                                        \n",
            " Encoder-7-FeedForward (FeedForward)   (None, None, 768)          4722432       ['Encoder-7-MultiHeadSelfAttention-Norm[\n",
            "                                                                                0][0]']                                 \n",
            "                                                                                                                        \n",
            " Encoder-7-FeedForward-Dropout (Dropou  (None, None, 768)         0             ['Encoder-7-FeedForward[0][0]']         \n",
            " t)                                                                                                                     \n",
            "                                                                                                                        \n",
            " Encoder-7-FeedForward-Add (Add)       (None, None, 768)          0             ['Encoder-7-MultiHeadSelfAttention-Norm[\n",
            "                                                                                0][0]',                                 \n",
            "                                                                                 'Encoder-7-FeedForward-Dropout[0][0]'] \n",
            "                                                                                                                        \n",
            " Encoder-7-FeedForward-Norm (LayerNorm  (None, None, 768)         1536          ['Encoder-7-FeedForward-Add[0][0]']     \n",
            " alization)                                                                                                             \n",
            "                                                                                                                        \n",
            " Encoder-8-MultiHeadSelfAttention (Mul  (None, None, 768)         2362368       ['Encoder-7-FeedForward-Norm[0][0]']    \n",
            " tiHeadAttention)                                                                                                       \n",
            "                                                                                                                        \n",
            " Encoder-8-MultiHeadSelfAttention-Drop  (None, None, 768)         0             ['Encoder-8-MultiHeadSelfAttention[0][0]\n",
            " out (Dropout)                                                                  ']                                      \n",
            "                                                                                                                        \n",
            " Encoder-8-MultiHeadSelfAttention-Add   (None, None, 768)         0             ['Encoder-7-FeedForward-Norm[0][0]',    \n",
            " (Add)                                                                           'Encoder-8-MultiHeadSelfAttention-Dropo\n",
            "                                                                                ut[0][0]']                              \n",
            "                                                                                                                        \n",
            " Encoder-8-MultiHeadSelfAttention-Norm  (None, None, 768)         1536          ['Encoder-8-MultiHeadSelfAttention-Add[0\n",
            "  (LayerNormalization)                                                          ][0]']                                  \n",
            "                                                                                                                        \n",
            " Encoder-8-FeedForward (FeedForward)   (None, None, 768)          4722432       ['Encoder-8-MultiHeadSelfAttention-Norm[\n",
            "                                                                                0][0]']                                 \n",
            "                                                                                                                        \n",
            " Encoder-8-FeedForward-Dropout (Dropou  (None, None, 768)         0             ['Encoder-8-FeedForward[0][0]']         \n",
            " t)                                                                                                                     \n",
            "                                                                                                                        \n",
            " Encoder-8-FeedForward-Add (Add)       (None, None, 768)          0             ['Encoder-8-MultiHeadSelfAttention-Norm[\n",
            "                                                                                0][0]',                                 \n",
            "                                                                                 'Encoder-8-FeedForward-Dropout[0][0]'] \n",
            "                                                                                                                        \n",
            " Encoder-8-FeedForward-Norm (LayerNorm  (None, None, 768)         1536          ['Encoder-8-FeedForward-Add[0][0]']     \n",
            " alization)                                                                                                             \n",
            "                                                                                                                        \n",
            " Encoder-9-MultiHeadSelfAttention (Mul  (None, None, 768)         2362368       ['Encoder-8-FeedForward-Norm[0][0]']    \n",
            " tiHeadAttention)                                                                                                       \n",
            "                                                                                                                        \n",
            " Encoder-9-MultiHeadSelfAttention-Drop  (None, None, 768)         0             ['Encoder-9-MultiHeadSelfAttention[0][0]\n",
            " out (Dropout)                                                                  ']                                      \n",
            "                                                                                                                        \n",
            " Encoder-9-MultiHeadSelfAttention-Add   (None, None, 768)         0             ['Encoder-8-FeedForward-Norm[0][0]',    \n",
            " (Add)                                                                           'Encoder-9-MultiHeadSelfAttention-Dropo\n",
            "                                                                                ut[0][0]']                              \n",
            "                                                                                                                        \n",
            " Encoder-9-MultiHeadSelfAttention-Norm  (None, None, 768)         1536          ['Encoder-9-MultiHeadSelfAttention-Add[0\n",
            "  (LayerNormalization)                                                          ][0]']                                  \n",
            "                                                                                                                        \n",
            " Encoder-9-FeedForward (FeedForward)   (None, None, 768)          4722432       ['Encoder-9-MultiHeadSelfAttention-Norm[\n",
            "                                                                                0][0]']                                 \n",
            "                                                                                                                        \n",
            " Encoder-9-FeedForward-Dropout (Dropou  (None, None, 768)         0             ['Encoder-9-FeedForward[0][0]']         \n",
            " t)                                                                                                                     \n",
            "                                                                                                                        \n",
            " Encoder-9-FeedForward-Add (Add)       (None, None, 768)          0             ['Encoder-9-MultiHeadSelfAttention-Norm[\n",
            "                                                                                0][0]',                                 \n",
            "                                                                                 'Encoder-9-FeedForward-Dropout[0][0]'] \n",
            "                                                                                                                        \n",
            " Encoder-9-FeedForward-Norm (LayerNorm  (None, None, 768)         1536          ['Encoder-9-FeedForward-Add[0][0]']     \n",
            " alization)                                                                                                             \n",
            "                                                                                                                        \n",
            " Encoder-10-MultiHeadSelfAttention (Mu  (None, None, 768)         2362368       ['Encoder-9-FeedForward-Norm[0][0]']    \n",
            " ltiHeadAttention)                                                                                                      \n",
            "                                                                                                                        \n",
            " Encoder-10-MultiHeadSelfAttention-Dro  (None, None, 768)         0             ['Encoder-10-MultiHeadSelfAttention[0][0\n",
            " pout (Dropout)                                                                 ]']                                     \n",
            "                                                                                                                        \n",
            " Encoder-10-MultiHeadSelfAttention-Add  (None, None, 768)         0             ['Encoder-9-FeedForward-Norm[0][0]',    \n",
            "  (Add)                                                                          'Encoder-10-MultiHeadSelfAttention-Drop\n",
            "                                                                                out[0][0]']                             \n",
            "                                                                                                                        \n",
            " Encoder-10-MultiHeadSelfAttention-Nor  (None, None, 768)         1536          ['Encoder-10-MultiHeadSelfAttention-Add[\n",
            " m (LayerNormalization)                                                         0][0]']                                 \n",
            "                                                                                                                        \n",
            " Encoder-10-FeedForward (FeedForward)  (None, None, 768)          4722432       ['Encoder-10-MultiHeadSelfAttention-Norm\n",
            "                                                                                [0][0]']                                \n",
            "                                                                                                                        \n",
            " Encoder-10-FeedForward-Dropout (Dropo  (None, None, 768)         0             ['Encoder-10-FeedForward[0][0]']        \n",
            " ut)                                                                                                                    \n",
            "                                                                                                                        \n",
            " Encoder-10-FeedForward-Add (Add)      (None, None, 768)          0             ['Encoder-10-MultiHeadSelfAttention-Norm\n",
            "                                                                                [0][0]',                                \n",
            "                                                                                 'Encoder-10-FeedForward-Dropout[0][0]']\n",
            "                                                                                                                        \n",
            " Encoder-10-FeedForward-Norm (LayerNor  (None, None, 768)         1536          ['Encoder-10-FeedForward-Add[0][0]']    \n",
            " malization)                                                                                                            \n",
            "                                                                                                                        \n",
            " Encoder-11-MultiHeadSelfAttention (Mu  (None, None, 768)         2362368       ['Encoder-10-FeedForward-Norm[0][0]']   \n",
            " ltiHeadAttention)                                                                                                      \n",
            "                                                                                                                        \n",
            " Encoder-11-MultiHeadSelfAttention-Dro  (None, None, 768)         0             ['Encoder-11-MultiHeadSelfAttention[0][0\n",
            " pout (Dropout)                                                                 ]']                                     \n",
            "                                                                                                                        \n",
            " Encoder-11-MultiHeadSelfAttention-Add  (None, None, 768)         0             ['Encoder-10-FeedForward-Norm[0][0]',   \n",
            "  (Add)                                                                          'Encoder-11-MultiHeadSelfAttention-Drop\n",
            "                                                                                out[0][0]']                             \n",
            "                                                                                                                        \n",
            " Encoder-11-MultiHeadSelfAttention-Nor  (None, None, 768)         1536          ['Encoder-11-MultiHeadSelfAttention-Add[\n",
            " m (LayerNormalization)                                                         0][0]']                                 \n",
            "                                                                                                                        \n",
            " Encoder-11-FeedForward (FeedForward)  (None, None, 768)          4722432       ['Encoder-11-MultiHeadSelfAttention-Norm\n",
            "                                                                                [0][0]']                                \n",
            "                                                                                                                        \n",
            " Encoder-11-FeedForward-Dropout (Dropo  (None, None, 768)         0             ['Encoder-11-FeedForward[0][0]']        \n",
            " ut)                                                                                                                    \n",
            "                                                                                                                        \n",
            " Encoder-11-FeedForward-Add (Add)      (None, None, 768)          0             ['Encoder-11-MultiHeadSelfAttention-Norm\n",
            "                                                                                [0][0]',                                \n",
            "                                                                                 'Encoder-11-FeedForward-Dropout[0][0]']\n",
            "                                                                                                                        \n",
            " Encoder-11-FeedForward-Norm (LayerNor  (None, None, 768)         1536          ['Encoder-11-FeedForward-Add[0][0]']    \n",
            " malization)                                                                                                            \n",
            "                                                                                                                        \n",
            " Encoder-12-MultiHeadSelfAttention (Mu  (None, None, 768)         2362368       ['Encoder-11-FeedForward-Norm[0][0]']   \n",
            " ltiHeadAttention)                                                                                                      \n",
            "                                                                                                                        \n",
            " Encoder-12-MultiHeadSelfAttention-Dro  (None, None, 768)         0             ['Encoder-12-MultiHeadSelfAttention[0][0\n",
            " pout (Dropout)                                                                 ]']                                     \n",
            "                                                                                                                        \n",
            " Encoder-12-MultiHeadSelfAttention-Add  (None, None, 768)         0             ['Encoder-11-FeedForward-Norm[0][0]',   \n",
            "  (Add)                                                                          'Encoder-12-MultiHeadSelfAttention-Drop\n",
            "                                                                                out[0][0]']                             \n",
            "                                                                                                                        \n",
            " Encoder-12-MultiHeadSelfAttention-Nor  (None, None, 768)         1536          ['Encoder-12-MultiHeadSelfAttention-Add[\n",
            " m (LayerNormalization)                                                         0][0]']                                 \n",
            "                                                                                                                        \n",
            " Encoder-12-FeedForward (FeedForward)  (None, None, 768)          4722432       ['Encoder-12-MultiHeadSelfAttention-Norm\n",
            "                                                                                [0][0]']                                \n",
            "                                                                                                                        \n",
            " Encoder-12-FeedForward-Dropout (Dropo  (None, None, 768)         0             ['Encoder-12-FeedForward[0][0]']        \n",
            " ut)                                                                                                                    \n",
            "                                                                                                                        \n",
            " Encoder-12-FeedForward-Add (Add)      (None, None, 768)          0             ['Encoder-12-MultiHeadSelfAttention-Norm\n",
            "                                                                                [0][0]',                                \n",
            "                                                                                 'Encoder-12-FeedForward-Dropout[0][0]']\n",
            "                                                                                                                        \n",
            " Encoder-12-FeedForward-Norm (LayerNor  (None, None, 768)         1536          ['Encoder-12-FeedForward-Add[0][0]']    \n",
            " malization)                                                                                                            \n",
            "                                                                                                                        \n",
            "========================================================================================================================\n",
            "Total params: 101,677,056\n",
            "Trainable params: 0\n",
            "Non-trainable params: 101,677,056\n",
            "________________________________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "uQY0yd0PPsVy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}